{
  "hash": "e0139832d23317ef145ce5d3e9c007d4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exponential\"\nformat:\n  html:\n    toc: true\n    toc-expansion: true\n---\n\n\n::: {.cell}\n\n:::\n\n\nAn Exponential survival model is a Generalized Linear Model just like logistic regression (previous page). We will estimate this model by writing down the log likelihood and carrying out numerical optimization with `optim`. As with the previous model, we will recover estimates that match those produced by canned functions.\n\nAs a reminder, the Exponential(1) distribution looks like this:\n\n::: {.cell}\n::: {.cell-output-display}\n![](exponential_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Without predictors\n\nAssume a data generating process of $n$ independent observations.\n\n* $t_1,\\dots,t_n\\sim\\text{Exponential}(\\lambda)$ are event times\n* $\\tilde{t}_1,\\dots,\\tilde{t}_n$ are observation times (either events or censoring)\n* $c_1,\\dots c_n$ indicate whether an observation is censored ($c_i = 1$) or the event occurs ($c_i = 0$)\n\nThe code below will simulate data with $\\lambda = 1$ and censoring at $t = 3$.\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulated <- tibble(id = 1:1000) |>\n  mutate(\n    # Exponential draws\n    t = rexp(n()),\n    # Trial cuts off at time 3\n    c = t > 3,\n    # Observed y is truncated at 3\n    t_tilde = ifelse(t > 3, 3, t)\n  )\n```\n:::\n\n\n## One-parameter likelihood in math\n\nLet $f(t,\\lambda)$ be the PDF of the exponential distribution. Let $F(t,\\lambda)$ be the CDF. The likelihood is the probability of observing the data if the parameter takes the value $\\lambda$. The observed data either tells us:\n\n1) an event occurred at time $t$ (uncensored)\n     * occurs with probability density $f(t\\mid\\lambda)$\n2) an event occurred at time greater than $t$ (censoring)\n     * occurs with probability $1 - F(t\\mid\\lambda)$\n     \nTranslating to math, the likelihood for a given observation is\n$$\n\\underbrace{\\left(f(\\tilde{t}_i\\mid\\lambda)\\right)^{1-c_i}}_{\\text{PDF at }\\tilde{t}_i\\text{ if uncensored}}\\quad\\times\\quad \\underbrace{\\left(1 - F(\\tilde{t}_i\\mid\\lambda)\\right)^{c_i}}_{\\text{Survival past }\\tilde{t}_i\\text{ if censored}}\n$$\n\nWe can put these together into a likelihood function for the vector of independent observations,\n$$\nL(\\vec{\\tilde{t}},\\vec{c}\\mid\\lambda) = \\prod_i \\left(f(\\tilde{t}_i\\mid\\lambda)\\right)^{1-c_i}\\left(1 - F(\\tilde{t}_i\\mid\\lambda)\\right)^{c_i}\n$$\nand take the log to get the log likelihood.\n$$\n\\ell(\\vec{\\tilde{t}},\\vec{c}\\mid\\lambda) = \\sum_i \\left((1-c_i)\\log[f(\\tilde{t}_i\\mid\\lambda)] + c_i\\log[1 - F(\\tilde{t}_i\\mid\\lambda)]\\right)\n$$\n\n## One-parameter likelihood in code\n\nWrite the log likelihood as a function in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_likelihood <- function(log_lambda, data) {\n  data |>\n    mutate(\n      likelihood_i = case_when(\n        c == 0 ~ dexp(t_tilde, rate = exp(log_lambda)),\n        c == 1 ~ pexp(t_tilde, rate = exp(log_lambda), lower.tail = FALSE)\n      )\n    ) |>\n    summarize(\n      log_likelihood = sum(log(likelihood_i))\n    ) |>\n    pull(log_likelihood)\n}\n```\n:::\n\n\n## One-parameter optimization\n\nUsing `optim`, we can numerically find the value $\\hat\\lambda$ that maximizes the log likelihood function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptimize.out <- optimize(\n  log_likelihood,  # function to optimize\n  lower = -1,      # lower limit of log_lambda candidates\n  upper = 1,       # upper limit of log_lambda candidates\n  maximum = TRUE,  # search for maximum\n  tol = .01,       # get within tol of truth\n  data = simulated # other argument to log_likelihood\n)\n```\n:::\n\n\nRemember that we set our parameter to be the log of the rate $\\lambda$. Thus, we need to exponentiate the estimated parameter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_lambda_hat <- optimize.out$maximum\nlambda_hat <- exp(log_lambda_hat) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.007788\n```\n\n\n:::\n:::\n\n\n## With predictors\n\nNow consider the setting where $\\lambda_i$ varies across units $i$ according to a Generalized Linear model,\n$$\n\\begin{aligned}\ny_i&\\sim\\text{Exponential}(\\lambda_i) \\\\\n\\log(\\lambda_i) &= \\vec{X}_i\\vec\\beta\n\\end{aligned}\n$$\n\nThe code below generates data to illustrate with two predictors, $X_1$ and $X_2$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulated <- tibble(id = 1:1000) |>\n  mutate(\n    x1 = rnorm(n()),\n    x2 = rnorm(n()),\n    lambda = exp(-1 + .5 * x1 + .5 * x2),\n    t = rexp(n(), rate = lambda),\n    # Create censoring at time 3\n    c = t > 3,\n    t_tilde = ifelse(t > 3, 3, t)\n  ) |>\n  select(x1, x2, c, t_tilde)\n```\n:::\n\n\n## Vector-parameter likelihood in math\n\nThe likelihood has not changed much from the case without predictors. The $\\lambda$ terms become $\\lambda_i$,\n$$\n\\ell(\\vec{\\tilde{t}},\\vec{c}\\mid\\vec\\lambda) = \\sum_i \\left((1-c_i)\\log[f(\\tilde{t}_i\\mid\\lambda_i)] + c_i\\log[1 - F(\\tilde{t}_i\\mid\\lambda_i)]\\right)\n$$\n\nand when coding this we will use the assumption that $\\lambda_i = \\text{exp}(\\vec{X}_i\\vec\\beta)$.\n\n## Vector-parameter likelihood in code\n\nThe log likelihood takes parameters and data and returns a likelihood value. When coding this, it is helpful that the `dexp` and `pexp` functions are the PDF and CDF of the Exponential distribution with `rate` parameter equal to $\\lambda$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_likelihood <- function(parameters, data, formula) {\n  \n  # Parameters are coefficients\n  beta <- parameters\n  \n  # Get the X matrix\n  X <- model.matrix(formula, data = data)\n  \n  # Calculate lambda values at that parameter vector\n  lambda <- exp(X %*% beta)\n  \n  # Calculate the likelihood\n  data |>\n    # Create a column with the lambda values for each case\n    mutate(lambda = lambda) |>\n    summarize(\n      # Use the formula from above, translated to code\n      log_likelihood = sum(\n        (1 - c) * log(dexp(t_tilde, rate = lambda)) + \n          c * log(1 - pexp(t_tilde, rate = lambda))\n      )\n    ) |>\n    # Pull the log likelihood value to return\n    pull(log_likelihood)\n}\n```\n:::\n\n\n## Vector-parameter optimization\n\nNow optimize with a call to `optim`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.out <- optim(\n  par = c(0,0,0),                # initial parameter values\n  fn = log_likelihood,           # function to optimize\n  control = list(fnscale = -1),  # find max instead of min\n  hessian = TRUE,                # also return the Hessian\n  data = simulated,              # passed to log_likelihood\n  formula = formula(t_tilde ~ x1 + x2) # passed to log_likelihood\n)\n```\n:::\n\n\nWe can extract the coefficient estimates.\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_hat <- optim.out$par |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.9116232  0.4979968  0.5117867\n```\n\n\n:::\n:::\n\n\nWe can extract the Hessian.\n\n::: {.cell}\n\n```{.r .cell-code}\nhessian <- optim.out$hessian\n```\n:::\n\n\nWe can solve for the variance-covariance matrix $\\hat{\\text{V}}(\\hat{\\vec\\beta})$: the negative inverse Hessian. In R, the `solve` function finds the inverse of a matrix.\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_hat_vcov <- -solve(hessian)\n```\n:::\n\n\nThis can give us our coefficients and standard errors (the square root of the diagonal of the variance covariance matrix).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  variable = c(\"Intercept\",\"x1\",\"x2\"),\n  beta = beta_hat,\n  se = sqrt(diag(beta_hat_vcov))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  variable    beta     se\n  <chr>      <dbl>  <dbl>\n1 Intercept -0.912 0.0408\n2 x1         0.498 0.0410\n3 x2         0.512 0.0398\n```\n\n\n:::\n:::\n\n\nWe can compare that to the output from logistic regression.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\ncanned_fit <- survreg(\n  Surv(time = t_tilde, event = 1 - c) ~ x1 + x2,\n  data = simulated,\n  dist = \"exponential\"\n)\nsummary(canned_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nsurvreg(formula = Surv(time = t_tilde, event = 1 - c) ~ x1 + \n    x2, data = simulated, dist = \"exponential\")\n              Value Std. Error     z      p\n(Intercept)  0.9117     0.0408  22.4 <2e-16\nx1          -0.4982     0.0410 -12.1 <2e-16\nx2          -0.5117     0.0398 -12.9 <2e-16\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -1145.5   Loglik(intercept only)= -1288.8\n\tChisq= 286.66 on 2 degrees of freedom, p= 5.7e-63 \nNumber of Newton-Raphson Iterations: 4 \nn= 1000 \n```\n\n\n:::\n:::\n\n\nNote that the canned fit is modeling the mean time to event $\\frac{1}{\\lambda}$ whereas our fit modeled the rate of events $\\lambda$. Because $\\beta$ coefficients are on the scale of $\\log(\\lamda)$, the canned fit estimates are the negative of our DIY estimates.\n\n## Simulate predictions\n\nWe can simulate predicted the hazard and survival probabilities. Suppose we are interested in the prediction at $(X_1,X_2) = (1,1)$. Define these data to predict,\n\n::: {.cell}\n\n```{.r .cell-code}\nto_predict <- tibble(x1 = 0, x2 = 1)\n```\n:::\n\ncreate an $X$ matrix at those values\n\n::: {.cell}\n\n```{.r .cell-code}\nX_new <- model.matrix(~ x1 + x2, data = to_predict)\n```\n:::\n\nand make predictions from that $X$ matrix.\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda_hat <- exp(X_new %*% beta_hat) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       [,1]\n1 0.6704297\n```\n\n\n:::\n:::\n\n\nWe may not just want the hazard: perhaps we want the probability of surviving past time $t = 2$. Recall that `pexp` is the CDF, and with the option `lower.tail = FALSE` it is the survival function.\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvival_hat <- pexp(2, rate = lambda_hat, lower.tail = FALSE)\n```\n:::\n\n\nTo get a standard error on the predictions, we can use simulation. We know that $\\hat{\\vec\\beta}$ is asymptotically multivariate normal. We can simulate many coefficient vectors $\\vec\\beta^*$ from that distribution,\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_star <- mvtnorm::rmvnorm(n = 1000, mean = beta_hat, sigma = beta_hat_vcov)\n```\n:::\n\nand we can generate a predicted hazard from each simulated value,\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda_star <- exp(X_new %*% t(beta_star))\n```\n:::\n\nand a predicted survival probability\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvival_star <- pexp(2, rate = lambda_star, lower.tail = FALSE)\n```\n:::\n\nThe standard error is the standard deviation of these simulated draws.\n\n::: {.cell}\n\n```{.r .cell-code}\nse_survial_hat <- sd(survival_star)\n```\n:::\n\n\n## Canned comparison\n\nWe can likewise predict with the canned version of the model,\n\n::: {.cell}\n\n```{.r .cell-code}\ncanned_linear_prediction <- predict(\n  canned_fit, \n  type = \"linear\", \n  newdata = to_predict\n)\n```\n:::\n\n\nRecall that this package has modeled $\\vec{X}_i\\beta = \\log(\\frac{1}{\\lambda_i}$. Thus we need to convert back to $\\lambda$.\n\n::: {.cell}\n\n```{.r .cell-code}\ncanned_lambda_hat <- 1 / exp(canned_linear_prediction)\n```\n:::\n\n\nNote that they are approximately the same!\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(\n  diy = lambda_hat[1,1],\n  canned = canned_lambda_hat\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        diy    canned\n1 0.6704297 0.6703185\n```\n\n\n:::\n:::\n\n\nAdvantages of the DIY coding yourself include\n\n* you know exactly how the model worked (e.g., modeling $\\lambda$ vs $1 / \\lambda$)\n* you know how to get standard errors for any quantity of interest\n* you can generalize to models that are not canned\n\n## Exercise\n\nThis exercise uses data from a medical trial that tracked survival outcomes of patients receiving heart transplants.\n\n> Crowley, J., & Hu, M. (1977). Covariance analysis of heart transplant survival data. Journal of the American Statistical Association, 72(357), 27-36.\n\nWe will access the data from the `survival` package in R. The trail enrolled people eligible for heart transplants, some of whom later received transplants and some did not. We will focus on survival outcomes post-transplant for transplant recipients. The code below prepares data on variables we will use.\n\n* `t` is time in years from transplant until either death or censoring\n* `c` is censoring, coded `TRUE` for censoring and `FALSE` for death\n* `age` is the patient's age at the time of transplant\n\n\n::: {.cell}\n\n```{.r .cell-code}\nheart_recipients <- tibble(survival::jasa) |> \n  # Keep those who received a transplant\n  filter(!is.na(tx.date)) |>\n  # Remove if died on the day of transplant\n  filter(tx.date != fu.date) |>\n  # Construct variables we will use\n  mutate(\n    # Age at transplant is difference between treatment date and birth date\n    age = as.numeric(difftime(tx.date, birth.dt, units = \"days\")) / 365.25,\n    # Time is difference between follow-up date and treatment date\n    t = as.numeric(difftime(fu.date, tx.date, units = \"days\")) / 365.25,\n    # Censoring is defined by follow-up status\n    c = fustat == 0\n  ) |>\n  select(age, c, t) |>\n  print(n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 68 × 3\n    age c           t\n  <dbl> <lgl>   <dbl>\n1  54.3 FALSE 0.0411 \n2  40.4 FALSE 0.00821\n3  51.0 FALSE 1.71   \n# ℹ 65 more rows\n```\n\n\n:::\n:::\n\n\nUsing these data:\n\n1. Fit an Exponential survival model in which the log hazard is a linear function of age at transplant.\n$$\nT_i\\sim \\text{Exponential}(\\lambda_i)\n$$\n$$\n\\log(\\lambda_i) = \\beta_0 + \\beta_1\\text{Age}_i\n$$\n\n2. At each observed value of the predictors, predict the hazard of death $\\hat\\lambda_i$.\n\n3. Convert the rate into an expected survival time $\\text{E}(T\\mid \\text{Age} = x)$. Note that the expected value of the Exponential distribution with rate $\\hat\\lambda_i$ is $\\frac{1}{\\hat\\lambda_i}$. Make a graph to visualize the expected survival time as a function of age.\n\n4. At each observed value of the predictors, calculate the probability of surviving at least 2 years post-transplant: $\\text{P}(T > 2\\mid \\text{Age} = x)$. Note that the survival function for the Exponential distribution with rate `lambda` at time `t` is `pexp(q = t, rate = lambda, lower.tail = FALSE)`. Plot these survival probabilities as a function of age.\n\n5. For at least one estimate from (3) or (4), construct a 95\\% confidence interval by simulating many draws of $\\vec\\beta^*$ from its estimated Multivariate Normal sampling distribution, translating each draw to a predicted quantity of interest. You can either construct your confidence interval by a Normal approximation to the predicted quantity of interest or by taking the middle 95\\% of simulated draws.\n\nSubmit either your raw R script or a PDF report (e.g., from .Rmd or .Qmd) that embeds your code.\n\nFull credit for carrying out estimation with `optim`. High partial credit for carrying out estimation using the `survreg()` function in the `survival` package. Note that with `survreg`, prediction with `type = response` will predict a scale parameter $\\frac{1}{\\lambda}$ rather than a rate parameter $\\lambda$.\n",
    "supporting": [
      "exponential_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}